I"ûG<details>
<summary><strong>Guest author</strong></summary>
This is a cross post by Yasuhiro Hara.
</details>

<p>Logging provides critical observability for your containerized application. As part of providing a fully managed Kubernetes control plane, Amazon Elastic Container Service for Kubernetes <a href="https://aws.amazon.com/eks/">Amazon EKS</a> provides automatic logging to <a href="https://aws.amazon.com/cloudwatch/">Amazon CloudWatch Logs</a>. This lets you see lots of information related to the Amazon EKS managed Kubernetes control plane by using the CloudWatch Logs console or the AWS Command Line Interface <a href="https://aws.amazon.com/cli/">AWS CLI</a>.</p>

<p>Worker nodes, the EC2 instances that run your containers, are managed by the Amazon EKS control plane, but they run in your account. On worker nodes, there are two types of logs:</p>

<ul>
  <li>System logs generated by kubelet, kube-proxy, or dockerd</li>
  <li>Application logs generated by your application containers</li>
</ul>

<p>In this post, I describe one of the ways to collect and search these worker node logs using Fluentd and CloudWatch Logs. I provide a sample manifest to deploy a DaemonSet to your worker nodes. The DaemonSet forwards the nodeâ€™s logs to CloudWatch Logs. I also show how to search these logs using the CloudWatch Logs console and the AWS CLI.</p>

<h2 id="kubernetes-logging-architecture">Kubernetes logging architecture</h2>

<p>By default, Kubernetes stores all logs on the Amazon EC2 instance. After an instance is terminated, all the logs are deleted if you donâ€™t export them or preserve the instanceâ€™s EBS volume. Additionally, it makes sense to see logs grouped by some meaningful dimension such as by service. However, pods tend to be distributed across instances, so it is hard to collate logs in a single, meaningful view.</p>

<p>To solve these problems, itâ€™s common to add additional cluster-level logging architecture to your Kubernetes cluster. Typically, this means that all logs are forwarded from the individual instances in the cluster to a logging backend where they are combined for higher-level reporting.</p>

<p>To forward logs from an instance to the logging backend, you need something between your containers and the backend. Because Kubernetes itself doesnâ€™t have any implementation or abstraction layer for this (as of version 1.10), choose and construct an architecture to do this job.</p>

<p>The most common pattern is to use a node logging agent as described in <a href="https://kubernetes.io/docs/concepts/cluster-administration/logging/">Logging Architecture</a>. With this pattern, you deploy a special set of pods on each instance, using DaemonSet to forward the logs on the instance to the backend. Therefore, all normal pods donâ€™t have to care about forwarding logs and they just put logs to STDOUT. In addition, the agent pods can also forward system logs, giving you better insight into the status and performance of your underlying infrastructure.</p>

<p>There are many options for logging backends. Many of these require you to implement and manage the backend yourself, which can be a lot of work. Managed services for logging are easier to implement and manage.</p>

<h3 id="fluentd-and-cloudwatch-logs">Fluentd and CloudWatch Logs</h3>
<p>Fluentd, a CNCF project like Kubernetes, is a popular logging agent. Fluentd has a plugin system and there are many useful plugins available for ingress and egress:</p>

<ul>
  <li>Using <a href="https://docs.fluentd.org/v0.12/articles/in_tail">in_tail</a>, you can easily tail and parse most log files.</li>
  <li>Using <a href="https://github.com/reevoo/fluent-plugin-systemd">fluent-plugin-systemd</a>, you can ingest systemd journal as well.</li>
</ul>

<p>There are multiple output plugins for various backends, such as <a href="https://github.com/awslabs/aws-fluent-plugin-kinesis">Amazon Kinesis</a>. To use these plugins with Fluentd, install them using RubyGems and configure with Fluentd config files.</p>

<p>Amazon CloudWatch Logs is a fully managed logging service from AWS. CloudWatch Logs is designed for storing and filtering logs, and integrating with other AWS services. You donâ€™t need to provision any resources in advance, just push log events to CloudWatch Logs. Then, you can filter to search logs, or count filtered logs and automatically alert to CloudWatch. Also, by adding subscriptions, you can process filtered logs in real time with AWS Lambda or stream them to Amazon Kinesis.</p>

<p>CloudWatch Logs has <strong>two</strong> dimensions:</p>

<p>Log streams are actual event streams of logs that you specify when you write logs.
Log groups are top-level resources that identify a group of log streams. You can filter or subscribe to log groups, so sometimes log groups are thought of as collections of log streams.
In this post, you use CloudWatch Logs as the logging backend and Fluentd as the logging agent on each EKS node. To send logs from Fluentd to CloudWatch Logs, use the <a href="https://github.com/fluent-plugins-nursery/fluent-plugin-cloudwatch-logs">fluent-plugin-cloudwatch-logs</a> plugin.</p>

<h3 id="deploy-fluentd-daemonset-to-your-eks-cluster">Deploy Fluentd DaemonSet to your EKS cluster</h3>

<p>To build the cluster-level logging architecture, start by deploying a DaemonSet for Fluentd to the EKS cluster. You can install and run Fluentd on the instance level outside Kubernetes, by using the cloud-init script or baked AMI for example. However, combining DaemonSet, Pod, and ConfigMap has more than enough capability:</p>

<ul>
  <li>You can run only one Fluentd agent on each node by using DaemonSet. This means updating the agent is easy compared to installing it for each instance.</li>
  <li>You can mount instance volumes to a pod. Even inside containers, Fluentd can read log files on the instance. It is possible to mount instance volumes with read-only permission for security.</li>
  <li>You can mount ConfigMap data onto volumes as well, so you can deploy fluentd config file via ConfigMap. No need to bake config file into container images or AMI, or deploy config files everywhere.
Also, you may want to add additional metadata to application logs in terms of Kubernetes, such as pod name, namespace, etc. There is another plugin of fluentd to do this, called <a href="https://github.com/fabric8io/fluent-plugin-kubernetes_metadata_filter">fluent-plugin-kubernetes_metadata_filter</a>. To use this plugin, the pods must have authorized access privilege to the Kubernetes API. Because EKS enables role-based access control (RBAC), you create a service account and role binding to do this.</li>
</ul>

<p>Application logs are written as files on /var/log/containers, but they are symbolic-linked to /var/log/pods and then /var/lib/docker/containers, which is where the actual log files are stored. Mount these directories onto the Fluentd container. System logs are managed by systemd and stored on /run/log/journal, so also mount this directory.</p>

<p>For the container image, use <a href="https://github.com/fluent/fluentd-kubernetes-daemonset">prebuilt container images</a> of Fluentd for Kubernetes. In these images, all required plugins are pre-installed at build time, so no additional work is required. There are various variations of images depending on backend output. For this post, use the <a href="https://github.com/fluent/fluentd-kubernetes-daemonset/blob/master/docker-image/v1.1/debian-cloudwatch/Dockerfile">v1.1-debian-cloudwatch</a> image as it contains the cloudwatch-logs and systemd plugins.</p>

<p>Finally, set up your IAM credentials because the Fluentd container must call the CloudWatch Logs API. Hereâ€™s an IAM policy to add to the IAM role for the EC2 instances.</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">{</span>
<span class="s2">"Version"</span>: <span class="s2">"2012-10-17"</span>,
<span class="s2">"Statement"</span>: <span class="o">[</span>
<span class="o">{</span>
<span class="s2">"Action"</span>: <span class="o">[</span>
<span class="s2">"logs:DescribeLogGroups"</span>,
<span class="s2">"logs:DescribeLogStreams"</span>,
<span class="s2">"logs:CreateLogGroup"</span>,
<span class="s2">"logs:CreateLogStream"</span>,
<span class="s2">"logs:PutLogEvents"</span>
<span class="o">]</span>,
<span class="s2">"Resource"</span>: <span class="s2">"*"</span>,
<span class="s2">"Effect"</span>: <span class="s2">"Allow"</span>
<span class="o">}</span>
<span class="o">]</span>
<span class="o">}</span>
</code></pre></div></div>

<p>Now, letâ€™s look into a sample manifest to deploy the Fluentd agent:</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>apiVersion: v1
kind: ServiceAccount
metadata:
name: fluentd
namespace: kube-system
<span class="nt">---</span>
apiVersion: rbac.authorization.k8s.io/v1beta1
kind: ClusterRole
metadata:
name: fluentd
namespace: kube-system
rules:
- apiGroups: <span class="o">[</span><span class="s2">""</span><span class="o">]</span>
resources:
- namespaces
- pods
verbs: <span class="o">[</span><span class="s2">"get"</span>, <span class="s2">"list"</span>, <span class="s2">"watch"</span><span class="o">]</span>
<span class="nt">---</span>
apiVersion: rbac.authorization.k8s.io/v1beta1
kind: ClusterRoleBinding
metadata:
name: fluentd
namespace: kube-system
roleRef:
apiGroup: rbac.authorization.k8s.io
kind: ClusterRole
name: fluentd
subjects:
- kind: ServiceAccount
name: fluentd
namespace: kube-system
<span class="nt">---</span>
apiVersion: v1
kind: ConfigMap
metadata:
name: fluentd-config
namespace: kube-system
labels:
k8s-app: fluentd-cloudwatch
data:
fluent.conf: |
@include containers.conf
@include systemd.conf

&lt;match fluent.<span class="k">**</span><span class="o">&gt;</span>
@type null
&lt;/match&gt;
containers.conf: |
&lt;<span class="nb">source</span><span class="o">&gt;</span>
@type <span class="nb">tail</span>
@id in_tail_container_logs
@label @containers
path /var/log/containers/<span class="k">*</span>.log
pos_file /var/log/fluentd-containers.log.pos
tag <span class="k">*</span>
read_from_head <span class="nb">true</span>
&lt;parse&gt;
@type json
time_format %Y-%m-%dT%H:%M:%S.%NZ
&lt;/parse&gt;
&lt;/source&gt;

&lt;label @containers&gt;
&lt;filter <span class="k">**</span><span class="o">&gt;</span>
@type kubernetes_metadata
@id filter_kube_metadata
&lt;/filter&gt;

&lt;filter <span class="k">**</span><span class="o">&gt;</span>
@type record_transformer
@id filter_containers_stream_transformer
&lt;record&gt;
stream_name <span class="k">${</span><span class="nv">tag_parts</span><span class="p">[3]</span><span class="k">}</span>
&lt;/record&gt;
&lt;/filter&gt;

&lt;match <span class="k">**</span><span class="o">&gt;</span>
@type cloudwatch_logs
@id out_cloudwatch_logs_containers
region <span class="s2">"#{ENV.fetch('REGION')}"</span>
log_group_name <span class="s2">"/eks/#{ENV.fetch('CLUSTER_NAME')}/containers"</span>
log_stream_name_key stream_name
remove_log_stream_name_key <span class="nb">true
</span>auto_create_stream <span class="nb">true</span>
&lt;buffer&gt;
flush_interval 5
chunk_limit_size 2m
queued_chunks_limit_size 32
retry_forever <span class="nb">true</span>
&lt;/buffer&gt;
&lt;/match&gt;
&lt;/label&gt;
systemd.conf: |
&lt;<span class="nb">source</span><span class="o">&gt;</span>
@type systemd
@id in_systemd_kubelet
@label @systemd
filters <span class="o">[{</span> <span class="s2">"_SYSTEMD_UNIT"</span>: <span class="s2">"kubelet.service"</span> <span class="o">}]</span>
&lt;entry&gt;
field_map <span class="o">{</span><span class="s2">"MESSAGE"</span>: <span class="s2">"message"</span>, <span class="s2">"_HOSTNAME"</span>: <span class="s2">"hostname"</span>, <span class="s2">"_SYSTEMD_UNIT"</span>: <span class="s2">"systemd_unit"</span><span class="o">}</span>
field_map_strict <span class="nb">true</span>
&lt;/entry&gt;
path /run/log/journal
pos_file /var/log/fluentd-journald-kubelet.pos
read_from_head <span class="nb">true
</span>tag kubelet.service
&lt;/source&gt;

&lt;<span class="nb">source</span><span class="o">&gt;</span>
@type systemd
@id in_systemd_kubeproxy
@label @systemd
filters <span class="o">[{</span> <span class="s2">"_SYSTEMD_UNIT"</span>: <span class="s2">"kubeproxy.service"</span> <span class="o">}]</span>
&lt;entry&gt;
field_map <span class="o">{</span><span class="s2">"MESSAGE"</span>: <span class="s2">"message"</span>, <span class="s2">"_HOSTNAME"</span>: <span class="s2">"hostname"</span>, <span class="s2">"_SYSTEMD_UNIT"</span>: <span class="s2">"systemd_unit"</span><span class="o">}</span>
field_map_strict <span class="nb">true</span>
&lt;/entry&gt;
path /run/log/journal
pos_file /var/log/fluentd-journald-kubeproxy.pos
read_from_head <span class="nb">true
</span>tag kubeproxy.service
&lt;/source&gt;

&lt;<span class="nb">source</span><span class="o">&gt;</span>
@type systemd
@id in_systemd_docker
@label @systemd
filters <span class="o">[{</span> <span class="s2">"_SYSTEMD_UNIT"</span>: <span class="s2">"docker.service"</span> <span class="o">}]</span>
&lt;entry&gt;
field_map <span class="o">{</span><span class="s2">"MESSAGE"</span>: <span class="s2">"message"</span>, <span class="s2">"_HOSTNAME"</span>: <span class="s2">"hostname"</span>, <span class="s2">"_SYSTEMD_UNIT"</span>: <span class="s2">"systemd_unit"</span><span class="o">}</span>
field_map_strict <span class="nb">true</span>
&lt;/entry&gt;
path /run/log/journal
pos_file /var/log/fluentd-journald-docker.pos
read_from_head <span class="nb">true
</span>tag docker.service
&lt;/source&gt;

&lt;label @systemd&gt;
&lt;filter <span class="k">**</span><span class="o">&gt;</span>
@type record_transformer
@id filter_systemd_stream_transformer
&lt;record&gt;
stream_name <span class="k">${</span><span class="nv">tag</span><span class="k">}</span>-<span class="k">${</span><span class="nv">record</span><span class="p">[</span><span class="s2">"hostname"</span><span class="p">]</span><span class="k">}</span>
&lt;/record&gt;
&lt;/filter&gt;

&lt;match <span class="k">**</span><span class="o">&gt;</span>
@type cloudwatch_logs
@id out_cloudwatch_logs_systemd
region <span class="s2">"#{ENV.fetch('REGION')}"</span>
log_group_name <span class="s2">"/eks/#{ENV.fetch('CLUSTER_NAME')}/systemd"</span>
log_stream_name_key stream_name
auto_create_stream <span class="nb">true
</span>remove_log_stream_name_key <span class="nb">true</span>
&lt;buffer&gt;
flush_interval 5
chunk_limit_size 2m
queued_chunks_limit_size 32
retry_forever <span class="nb">true</span>
&lt;/buffer&gt;
&lt;/match&gt;
&lt;/label&gt;
<span class="nt">---</span>
apiVersion: extensions/v1beta1
kind: DaemonSet
metadata:
name: fluentd-cludwatch
namespace: kube-system
labels:
k8s-app: fluentd-cloudwatch
spec:
template:
metadata:
labels:
k8s-app: fluentd-cloudwatch
spec:
serviceAccountName: fluentd
terminationGracePeriodSeconds: 30
<span class="c"># Because the image's entrypoint requires to write on /fluentd/etc but we mount configmap there which is read-only,</span>
<span class="c"># this initContainers workaround or other is needed.</span>
<span class="c"># See https://github.com/fluent/fluentd-kubernetes-daemonset/issues/90</span>
initContainers:
- name: copy-fluentd-config
image: busybox
<span class="nb">command</span>: <span class="o">[</span><span class="s1">'sh'</span>, <span class="s1">'-c'</span>, <span class="s1">'cp /config-volume/..data/* /fluentd/etc'</span><span class="o">]</span>
volumeMounts:
- name: config-volume
mountPath: /config-volume
- name: fluentdconf
mountPath: /fluentd/etc
containers:
- name: fluentd-cloudwatch
image: fluent/fluentd-kubernetes-daemonset:v1.1-debian-cloudwatch
<span class="nb">env</span>:
- name: REGION
value: us-west-2
- name: CLUSTER_NAME
value: demo
resources:
limits:
memory: 200Mi
requests:
cpu: 100m
memory: 200Mi
volumeMounts:
- name: config-volume
mountPath: /config-volume
- name: fluentdconf
mountPath: /fluentd/etc
- name: varlog
mountPath: /var/log
- name: varlibdockercontainers
mountPath: /var/lib/docker/containers
readOnly: <span class="nb">true</span>
- name: runlogjournal
mountPath: /run/log/journal
readOnly: <span class="nb">true
</span>volumes:
- name: config-volume
configMap:
name: fluentd-config
- name: fluentdconf
emptyDir: <span class="o">{}</span>
- name: varlog
hostPath:
path: /var/log
- name: varlibdockercontainers
hostPath:
path: /var/lib/docker/containers
- name: runlogjournal
hostPath:
path: /run/log/journal
</code></pre></div></div>

<p>To use this sample directly, modify the environment variables REGION and CLUSTER_NAME placed at the line 195â€“199. REGION is used to create the CloudWatch Logs log group, and CLUSTER_NAME is used in the log group name. Run the following command:</p>

<p>kubectl create -f manifest.yaml</p>

<p>Thatâ€™s it! To troubleshoot, view the output of Fluentd containers using the following command:</p>

<p>kubectl logs -l k8s-app=fluentd-cloudwatch -n kube-system</p>

<p>Next, search the published logs.</p>

<h3 id="search-logs-with-cloudwatch-logs">Search logs with CloudWatch Logs</h3>

<p>CloudWatch Logs is a managed logging service. You can search logs directly through the console, AWS CLI, or SDK.</p>

<p>CloudWatch console</p>

<p>Open the <a href="https://console.aws.amazon.com/cloudwatch/home">CloudWatch Logs</a> console.</p>

<p>Scroll down and select a log group named /eks/CLUSTER_NAME/containers.</p>

<p><img src="/images/cw1.png" alt="CloudWatch Logs - Log Groups" /></p>

<p><img src="/images/cw2.png" alt="CloudWatch Logs - logs" /></p>

<p><img src="/images/cw3.png" alt="CloudWatch Logs - all streams" /></p>

<p><img src="/images/cw4.png" alt="CloudWatch Logs - filtering stream" /></p>

<h2 id="summary">Summary</h2>

<p>In this post, I described the Kubernetes logging pattern, especially cluster-level logging using a node agent. I then introduced Fluentd and CloudWatch Logs as tools for forwarding and storing logs, and showed a sample manifest to deploy such architecture on your EKS cluster. Also, I showed how to search logs stored on CloudWatch Logs from the console.</p>

<p>With this architecture, you can easily deploy a centralized logging system onto your cluster to have more visibility into your cluster. Because both Fluentd and CloudWatch Logs are flexible, you can configure this implementation as needed.</p>

<hr />
:ET